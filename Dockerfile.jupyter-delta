FROM jupyter/scipy-notebook:latest

USER root

# Instalar Java 17 (necessário para Spark)
RUN apt-get update && \
    apt-get install -y -qq openjdk-17-jdk-headless && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Configurar JAVA_HOME
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH=$JAVA_HOME/bin:$PATH

# Instalar pacotes Python como root primeiro
RUN pip install --no-cache-dir delta-spark pyspark s3fs boto3 duckdb pyarrow pandas

# Baixar JARs necessários para S3A (como root)
RUN mkdir -p /opt/spark/jars && \
    cd /opt/spark/jars && \
    wget -q https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar && \
    wget -q https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar && \
    chmod -R 755 /opt/spark

# Verificar Java
RUN java -version

USER jovyan
