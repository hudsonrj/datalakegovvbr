# ğŸ”§ SoluÃ§Ã£o: Erro scala.collection.SeqOps no Delta Lake

## âŒ Problema

Erro ao usar Delta Lake com Spark:
```
java.lang.NoClassDefFoundError: scala/collection/SeqOps
```

## ğŸ” Causa

Incompatibilidade entre versÃµes do Delta Lake e Spark. O erro ocorre porque:
- Spark 4.0.1 estÃ¡ instalado
- Delta Lake 4.0.0 pode ter incompatibilidade de versÃ£o do Scala
- Os JARs do Delta Lake nÃ£o estÃ£o sendo carregados corretamente

## âœ… SoluÃ§Ã£o

O script `configurar_spark.py` e o notebook `CONFIGURAR_SPARK.ipynb` foram atualizados para:

1. **Detectar automaticamente a versÃ£o do Spark**
2. **Usar os JARs corretos do Delta Lake** compatÃ­veis com cada versÃ£o:
   - Spark 4.x â†’ Delta Lake 4.0.0 (Scala 2.13)
   - Spark 3.5.x â†’ Delta Lake 3.0.0 (Scala 2.12)
   - Spark 3.x â†’ Delta Lake 2.4.0 (Scala 2.12)

3. **Carregar os JARs explicitamente** via `spark.jars.packages`

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Usar o Notebook Atualizado

1. Abra o Jupyter Lab: http://localhost:8889/lab
2. Abra: `CONFIGURAR_SPARK.ipynb`
3. Execute todas as cÃ©lulas na ordem

### OpÃ§Ã£o 2: Usar o Script Python

```python
exec(open('configurar_spark.py').read())
```

## ğŸ“‹ VersÃµes CompatÃ­veis

| Spark | Delta Lake | Scala | Pacote JAR |
|-------|-----------|-------|------------|
| 4.0.x | 4.0.0 | 2.13 | `io.delta:delta-spark_2.13:4.0.0` |
| 3.5.x | 3.0.0 | 2.12 | `io.delta:delta-spark_2.12:3.0.0` |
| 3.x   | 2.4.0 | 2.12 | `io.delta:delta-spark_2.12:2.4.0` |

## ğŸ”„ Fallback

Se o Delta Lake nÃ£o funcionar, o script cria uma Spark Session sem Delta (modo fallback) que permite usar Parquet normalmente.

## âœ… VerificaÃ§Ã£o

ApÃ³s executar, teste:

```python
# Verificar Spark
print(f"VersÃ£o Spark: {spark.version}")

# Teste bÃ¡sico
test_df = spark.range(5)
test_df.show()
```

Se funcionar sem erros, estÃ¡ tudo correto!
