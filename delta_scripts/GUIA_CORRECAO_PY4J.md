# üîß Guia de Corre√ß√£o - Erro Py4J Network Error

## ‚ùå Erro Encontrado

```
Py4JNetworkError: Answer from Java side is empty
```

Este erro ocorre quando h√° problemas de comunica√ß√£o entre Python (PySpark) e Java (Spark).

## ‚úÖ Solu√ß√£o R√°pida

### Op√ß√£o 1: Usar o Notebook de Corre√ß√£o (Recomendado)

1. Abra o Jupyter Lab: http://49.13.203.251:8889
2. Navegue at√© o arquivo: `FIX_PY4J_ERROR.ipynb`
3. Execute todas as c√©lulas em ordem
4. Aguarde a conclus√£o (pode levar alguns segundos)

### Op√ß√£o 2: Executar Script Python Diretamente

No Jupyter Lab, crie uma nova c√©lula e execute:

```python
# Executar script de corre√ß√£o
exec(open('/home/jovyan/work/fix_spark_py4j.py').read())
```

### Op√ß√£o 3: Usar Script de Configura√ß√£o Atualizado

```python
# Usar script de configura√ß√£o atualizado
exec(open('/home/jovyan/work/configurar_spark.py').read())
```

## üîç O que o Script Faz

O script `fix_spark_py4j.py` executa os seguintes passos:

1. **Limpa Ambiente**
   - Para todas as sess√µes Spark existentes
   - Finaliza processos Java do Spark
   - Limpa mem√≥ria (garbage collection)

2. **Verifica e Libera Portas** ‚≠ê NOVO
   - Verifica portas comuns do Spark (4040, 8080, 7077, etc.)
   - Mata processos que est√£o usando essas portas
   - Evita erros "Connection refused"

3. **Configura Vari√°veis de Ambiente**
   - Configura `JAVA_HOME` automaticamente
   - Define vari√°veis de rede (`SPARK_LOCAL_IP`, `SPARK_DRIVER_HOST`)
   - Configura paths do Python

4. **Verifica Recursos**
   - Verifica mem√≥ria dispon√≠vel
   - Ajusta configura√ß√µes de mem√≥ria do Spark automaticamente

5. **Cria Spark Session Robusta**
   - Configura√ß√µes de timeout aumentadas
   - Garbage Collector otimizado (G1GC)
   - Configura√ß√µes de rede IPv4
   - **Portas din√¢micas (0)** para evitar conflitos ‚≠ê NOVO
   - Suporte a S3A (MinIO)

6. **Verifica Conectividade de Rede** ‚≠ê NOVO
   - Testa conectividade de socket antes de criar sess√£o
   - Identifica problemas de rede precocemente

7. **Testa Conectividade Py4J**
   - Testa comunica√ß√£o Py4J
   - Verifica se Spark est√° respondendo

## üìã Configura√ß√µes Aplicadas

### Mem√≥ria
- **Driver Memory**: 2GB (ou menos se pouca mem√≥ria dispon√≠vel)
- **Executor Memory**: 2GB (ou menos se pouca mem√≥ria dispon√≠vel)
- **Max Result Size**: 1GB

### Timeouts
- **Network Timeout**: 1200s (20 minutos)
- **Heartbeat Interval**: 60s
- **S3A Connection Timeout**: 60000ms

### Portas
- **Portas Din√¢micas**: Todas as portas do Spark s√£o configuradas como `0` (din√¢micas)
  - `spark.driver.port = 0`
  - `spark.blockManager.port = 0`
  - `spark.broadcast.port = 0`
  - `spark.fileserver.port = 0`
  - `spark.replClassServer.port = 0`
  - `spark.ui.port = 0`
- Isso evita conflitos de porta e erros "Connection refused"

### Java Options
- `-Dio.netty.tryReflectionSetAccessible=true` - Permite reflex√£o do Netty
- `-XX:+UseG1GC` - Usa G1 Garbage Collector
- `-XX:MaxGCPauseMillis=200` - Limita pausas do GC
- `-Djava.net.preferIPv4Stack=true` - Prefere IPv4
- `-Djava.awt.headless=true` - Modo headless (sem interface gr√°fica)

## üö® Se o Erro Persistir

### 1. Reiniciar Container

```bash
docker restart govbr-jupyter-delta
```

Aguarde alguns segundos e tente novamente.

### 2. Verificar Logs

```bash
docker logs govbr-jupyter-delta
```

Procure por erros relacionados a:
- Mem√≥ria (OutOfMemoryError)
- Portas em uso
- Problemas de Java

### 3. Verificar Mem√≥ria Dispon√≠vel

```bash
docker exec -it govbr-jupyter-delta free -h
```

Se houver pouca mem√≥ria dispon√≠vel, o script ajustar√° automaticamente.

### 4. Verificar Processos Java

```bash
docker exec -it govbr-jupyter-delta ps aux | grep java
```

Se houver muitos processos Java, pode ser necess√°rio reiniciar o container.

### 5. Verificar Portas

```bash
docker exec -it govbr-jupyter-delta netstat -tuln | grep -E "4040|8080"
```

Se as portas estiverem em uso, pode ser necess√°rio parar outros servi√ßos.

## üí° Dicas

1. **Sempre execute o script de corre√ß√£o primeiro** antes de usar Spark em um novo notebook
2. **N√£o execute m√∫ltiplas sess√µes Spark simultaneamente** - pare uma antes de criar outra
3. **Se o erro ocorrer durante uma opera√ß√£o longa**, pode ser falta de mem√≥ria - reduza o tamanho dos dados processados
4. **Use `spark.stop()`** quando terminar de usar Spark para liberar recursos

## üìù Exemplo de Uso Ap√≥s Corre√ß√£o

```python
# 1. Executar corre√ß√£o (se necess√°rio)
exec(open('/home/jovyan/work/fix_spark_py4j.py').read())

# 2. Usar Spark normalmente
df = spark.range(10)
df.show()

# 3. Ler dados do MinIO
df = spark.read.parquet("s3a://govbr/bronze/ibge/municipios/")
df.show(5)

# 4. Quando terminar, parar Spark (opcional)
# spark.stop()
```

## üîó Arquivos Relacionados

- `fix_spark_py4j.py` - Script principal de corre√ß√£o
- `FIX_PY4J_ERROR.ipynb` - Notebook de corre√ß√£o
- `configurar_spark.py` - Script de configura√ß√£o padr√£o (atualizado)
- `CONFIGURAR_SPARK.ipynb` - Notebook de configura√ß√£o padr√£o

## üìû Suporte

Se o problema persistir ap√≥s seguir todos os passos:

1. Verifique os logs completos do container
2. Verifique a vers√£o do Spark: `spark.version`
3. Verifique a vers√£o do Java: `java -version`
4. Verifique a mem√≥ria dispon√≠vel no sistema
